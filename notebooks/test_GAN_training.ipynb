{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "import glob\n",
    "from multiprocessing import cpu_count\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "## 3rd party\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFilter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "_path = \"..\"\n",
    "if _path not in sys.path:\n",
    "    sys.path.append(_path)\n",
    "from lib.dataset import TextArtDataLoader, AlignCollate, ImageBatchSampler\n",
    "from lib.config import Config\n",
    "from lib.arch import Generator, Discriminator\n",
    "from lib.utils import GANLoss\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GANLoss('vanilla')\n",
    "# pred = torch.Tensor([[0.7, 0.3], [0.80, 0.20], [0.42, 0.58]])\n",
    "pred = torch.rand((64, 512, 4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5087), 0.0)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan(pred, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = torch.Tensor([1.0])\n",
    "random_mul = torch.rand(1) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9722])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label - random_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'united'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "# N_WORKERS = cpu_count() - 1\n",
    "N_WORKERS = 0\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "N_EPOCHS = 10\n",
    "LR_G = 1e-4\n",
    "LR_D = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextArtDataLoader(DATA_DIR, CONFIG, mode='train')\n",
    "val_dataset = TextArtDataLoader(DATA_DIR, CONFIG, mode='val')\n",
    "test_dataset = TextArtDataLoader(DATA_DIR, CONFIG, mode='test')\n",
    "\n",
    "train_align_collate = AlignCollate(CONFIG, 'train')\n",
    "val_align_collate = AlignCollate(CONFIG, 'val')\n",
    "\n",
    "train_batch_sampler = ImageBatchSampler(DATA_DIR, CONFIG, mode='train')\n",
    "val_batch_sampler = ImageBatchSampler(DATA_DIR, CONFIG, mode='val')\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=N_WORKERS,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=train_align_collate,\n",
    "                          sampler=train_batch_sampler,\n",
    "                         )\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=N_WORKERS,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=val_align_collate,\n",
    "                          sampler=val_batch_sampler\n",
    "                         )\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=N_WORKERS,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=None,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, (image, wv_tensor, fake_wv_tensor) in enumerate(train_loader):\n",
    "    print(\"IMAGE:\", image.shape)\n",
    "    print(\"WV:\", wv_tensor.shape)\n",
    "    print(\"Fake WV:\", fake_wv_tensor.shape)\n",
    "    \n",
    "    print(\"WVs\")\n",
    "    for wvs in wv_tensor:\n",
    "        for wv in wvs:\n",
    "            wv = np.array(wv)\n",
    "            word, prob = train_loader.dataset.word2vec_model.wv.similar_by_vector(wv)[0]\n",
    "            print(\"{}/{:.3f}\".format(word, prob), end=' ')\n",
    "        print()\n",
    "    \n",
    "    print(\"\\nFake WVs\")\n",
    "    for fake_wvs in fake_wv_tensor:\n",
    "        for fake_wv in fake_wvs:\n",
    "            fake_wv = np.array(fake_wv)\n",
    "            fake_word, prob = train_loader.dataset.word2vec_model.wv.similar_by_vector(fake_wv)[0]\n",
    "            print(\"{}/{:.3f}\".format(fake_word, prob), end=' ')\n",
    "        print()\n",
    "    \n",
    "    images = np.array(image)\n",
    "    for img in images:\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wv_tensors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7ff64d9c2ca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwv_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wv_tensors' is not defined"
     ]
    }
   ],
   "source": [
    "wv_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.Tensor(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = wv_tensor.reshape(images.shape)\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((images, r), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(CONFIG).to(DEVICE)\n",
    "G.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator(CONFIG).to(DEVICE)\n",
    "D.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = train_loader\n",
    "\n",
    "optimizer_d = torch.optim.Adam(D.parameters(), lr=LR_D, weight_decay=WEIGHT_DECAY)\n",
    "optimizer_g = torch.optim.Adam(G.parameters(), lr=LR_G, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "loss = nn.BCELoss().to(DEVICE)\n",
    "loss_ls = lambda x, y: 0.5 * torch.mean((x - y) ** 2)\n",
    "loss_ms = nn.MSELoss().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.train()\n",
    "D.train()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    total_g_loss = 0.0\n",
    "    total_d_loss = 0.0\n",
    "    \n",
    "    for i, (images, word_vectors_tensor) in enumerate(data_loader):\n",
    "\n",
    "        batch_size = images.size()[0]\n",
    "        \n",
    "        real_label = torch.full((batch_size,), 1.0, device=DEVICE)\n",
    "        fake_label = torch.full((batch_size,), 0.0, device=DEVICE)\n",
    "\n",
    "        images = images.to(DEVICE)\n",
    "        word_vectors_tensor = word_vectors_tensor.to(DEVICE)\n",
    "        word_sequence = word_vectors_tensor[:, 0, :].unsqueeze(2).unsqueeze(3)\n",
    "        \n",
    "        # Discriminator pass for real\n",
    "        D.zero_grad()\n",
    "        output_real = D(images).view(-1)\n",
    "        loss_real = loss(output_real, real_label)\n",
    "        loss_real.backward(retain_graph=False)\n",
    "        \n",
    "        # Discriminator pass for fake\n",
    "        fake = G(word_sequence)\n",
    "        output_fake = D(fake.detach()).view(-1)\n",
    "        loss_fake = loss(output_fake, fake_label)\n",
    "        loss_fake.backward(retain_graph=False)\n",
    "        loss_d = loss_real + loss_fake\n",
    "        \n",
    "        # Discriminator update\n",
    "        optimizer_d.zero_grad()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Generator pass\n",
    "        G.zero_grad()\n",
    "        output_fake = D(fake).view(-1)\n",
    "        loss_g = loss(output_fake, real_label)\n",
    "        loss_g.backward(retain_graph=False)\n",
    "\n",
    "        # Generator backward pass\n",
    "        optimizer_g.zero_grad()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        # Update total loss\n",
    "        total_g_loss += loss_g.item()\n",
    "        total_d_loss += loss_d.item()\n",
    "\n",
    "        # Print logs\n",
    "        if i % 20 == 0:\n",
    "            print('[{0:3d}/{1}] {2:3d}/{3} loss_g: {4:.4f} | loss_d: {5:4f}'\n",
    "                .format(epoch + 1, N_EPOCHS, i + 1, len(data_loader), loss_g.item(), loss_d.item()))\n",
    "            \n",
    "    print(\"Epoch time: {}\".format(time.time() - epoch_start))\n",
    "            \n",
    "    break\n",
    "            \n",
    "    \n",
    "#     # Save your model weights\n",
    "#     if (epoch + 1) % 5 == 0:\n",
    "#         save_dict = {\n",
    "#             'g':G.state_dict(), \n",
    "#             'g_optim':optimizer_g.state_dict(),\n",
    "#             'd': D.state_dict(),\n",
    "#             'd_optim': optimizer_d.state_dict()\n",
    "#         }\n",
    "#         torch.save(save_dict, os.path.join(MODEL_PATH, 'checkpoint_{}.pth'.format(epoch + 1)))\n",
    "        \n",
    "#     # Merge noisy input, ground truth and network output so that you can compare your results side by side\n",
    "#     out = torch.cat([img, fake], dim=2).detach().cpu().clamp(0.0, 1.0)\n",
    "#     vutils.save_image(out, os.path.join(OUTPUT_PATH, \"{}_{}.png\".format(epoch, i)), normalize=True)\n",
    "    \n",
    "#     # Calculate avarage loss for the current epoch\n",
    "#     avg_g_loss = total_g_loss / len(data_loader)\n",
    "#     avg_d_loss = total_d_loss / len(data_loader)\n",
    "#     print('Epoch[{}] Training Loss G: {:4f} | D: {:4f}'.format(epoch + 1, avg_g_loss, avg_d_loss))\n",
    "    \n",
    "#     cache_train_g.append(avg_g_loss)\n",
    "#     cache_train_d.append(avg_d_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.3",
   "language": "python",
   "name": "pytorch1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
