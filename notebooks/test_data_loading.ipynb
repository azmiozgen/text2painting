{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "import glob\n",
    "from multiprocessing import cpu_count\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "## 3rd party\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFilter\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "_path = \"..\"\n",
    "if _path not in sys.path:\n",
    "    sys.path.append(_path)\n",
    "from lib.dataset import TextArtDataLoader, AlignCollate, ImageBatchSampler\n",
    "from lib.config import Config\n",
    "# from lib.preprocess import (pad_image, crop_edges_lr, )\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'united'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "# N_WORKERS = cpu_count() - 1\n",
    "N_WORKERS = 0\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextArtDataLoader(DATA_DIR, CONFIG, mode='train')\n",
    "val_dataset = TextArtDataLoader(DATA_DIR, CONFIG, mode='val')\n",
    "test_dataset = TextArtDataLoader(DATA_DIR, CONFIG, mode='test')\n",
    "\n",
    "train_align_collate = AlignCollate(CONFIG, 'train')\n",
    "val_align_collate = AlignCollate(CONFIG, 'val')\n",
    "\n",
    "train_batch_sampler = ImageBatchSampler(DATA_DIR, CONFIG, mode='train')\n",
    "val_batch_sampler = ImageBatchSampler(DATA_DIR, CONFIG, mode='val')\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=N_WORKERS,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=train_align_collate,\n",
    "                          sampler=train_batch_sampler,\n",
    "                         )\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=N_WORKERS,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=val_align_collate,\n",
    "                          sampler=val_batch_sampler\n",
    "                         )\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=N_WORKERS,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=None,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, (image, wv_tensor, fake_wv_tensor) in enumerate(train_loader):\n",
    "    print(\"IMAGE:\", image.shape)\n",
    "    print(\"WV:\", wv_tensor.shape)\n",
    "    print(\"Fake WV:\", fake_wv_tensor.shape)\n",
    "    \n",
    "    print(\"WVs\")\n",
    "    for wvs in wv_tensor:\n",
    "        for wv in wvs:\n",
    "            wv = np.array(wv)\n",
    "            word, prob = train_loader.dataset.word2vec_model.wv.similar_by_vector(wv)[0]\n",
    "            print(\"{}/{:.3f}\".format(word, prob), end=' ')\n",
    "        print()\n",
    "    \n",
    "    print(\"\\nFake WVs\")\n",
    "    for fake_wvs in fake_wv_tensor:\n",
    "        for fake_wv in fake_wvs:\n",
    "            fake_wv = np.array(fake_wv)\n",
    "            fake_word, prob = train_loader.dataset.word2vec_model.wv.similar_by_vector(fake_wv)[0]\n",
    "            print(\"{}/{:.3f}\".format(fake_word, prob), end=' ')\n",
    "        print()\n",
    "    \n",
    "    images = np.array(image)\n",
    "    for img in images:\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = train_dataset.word2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.wv.similar_by_word('cat', topn=None).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.wv.similar_by_vector(np.array(word_vector), topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.wv.similar_by_vector(np.array(word_vector), topn=1000000)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.wv.similar_by_vector(vector, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = mod.wv['cat']\n",
    "vector2 = mod.wv['dog']\n",
    "a = np.stack((vector1, vector2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words = np.array(mod.wv.similar_by_vector(vector, topn=20))\n",
    "np.random.choice(similar_words[:,0], 3, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(image)[1].transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(img <= 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(img >= -1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = ImageBatchSampler('united', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = batch_sampler.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Group batches\n",
    "df_n_labels_grouped = df.groupby(by=pd.cut(df['n_labels'], [0, 5, 7, 11, 1000]))\n",
    "for key1, item1 in df_n_labels_grouped:\n",
    "    print(\"\\nN LABEL GROUP\", key1)\n",
    "    df1 = df_n_labels_grouped.get_group(key1)\n",
    "    df_width_grouped = df1.groupby(by=pd.cut(df1['width'], [0, 500, 700, 1000, 10000]))\n",
    "    for key2, item2 in df_width_grouped:\n",
    "        print(\"\\tWIDTH GROUP\", key2)\n",
    "        df2 = df_width_grouped.get_group(key2)\n",
    "        df_height_grouped = df2.groupby(by=pd.cut(df2['height'], [0, 590, 10000]))\n",
    "        for key3, item3 in df_height_grouped:\n",
    "            print(\"\\t\\tHEIGHT GROUP\", key3)\n",
    "#             print(df_height_grouped.get_group(key3), \"\\n\\n\")\n",
    "            print('\\t\\t\\t', len(df_height_grouped.get_group(key3).index), 'samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['index'].isin(batches[index])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.3",
   "language": "python",
   "name": "pytorch1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
