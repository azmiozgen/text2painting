{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "import glob\n",
    "from multiprocessing import cpu_count\n",
    "import os\n",
    "import sys\n",
    "\n",
    "## 3rd party\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFilter\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "_path = \"..\"\n",
    "if _path not in sys.path:\n",
    "    sys.path.append(_path)\n",
    "from lib.dataset import TextArtDataLoader, AlignCollate, ImageBatchSampler\n",
    "from lib.config import Config\n",
    "# from lib.preprocess import (pad_image, crop_edges_lr, )\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD2VEC_MODEL_FILE = \"../models/deviant_wiki_word2vec.model\"\n",
    "BATCH_SIZE = 4\n",
    "# N_WORKERS = cpu_count() - 1\n",
    "N_WORKERS = 1\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextArtDataLoader('united', WORD2VEC_MODEL_FILE, mode='train')\n",
    "val_dataset = TextArtDataLoader('united', WORD2VEC_MODEL_FILE, mode='val')\n",
    "test_dataset = TextArtDataLoader('united', WORD2VEC_MODEL_FILE, mode='test')\n",
    "train_align_collate = AlignCollate('train',\n",
    "                                   CONFIG.MEAN,\n",
    "                                   CONFIG.STD,\n",
    "                                   CONFIG.IMAGE_SIZE_HEIGHT,\n",
    "                                   CONFIG.IMAGE_SIZE_WIDTH,\n",
    "                                   horizontal_flipping=CONFIG.HORIZONTAL_FLIPPING,\n",
    "                                   random_rotation=CONFIG.RANDOM_ROTATION,\n",
    "                                   color_jittering=CONFIG.COLOR_JITTERING,\n",
    "                                   random_grayscale=CONFIG.RANDOM_GRAYSCALE,\n",
    "                                   random_channel_swapping=CONFIG.RANDOM_CHANNEL_SWAPPING,\n",
    "                                   random_gamma=CONFIG.RANDOM_GAMMA,\n",
    "                                   random_resolution=CONFIG.RANDOM_RESOLUTION)\n",
    "val_align_collate = AlignCollate('val',\n",
    "                                   CONFIG.MEAN,\n",
    "                                   CONFIG.STD,\n",
    "                                   CONFIG.IMAGE_SIZE_HEIGHT,\n",
    "                                   CONFIG.IMAGE_SIZE_WIDTH,\n",
    "                                   horizontal_flipping=CONFIG.HORIZONTAL_FLIPPING,\n",
    "                                   random_rotation=CONFIG.RANDOM_ROTATION,\n",
    "                                   color_jittering=CONFIG.COLOR_JITTERING,\n",
    "                                   random_grayscale=CONFIG.RANDOM_GRAYSCALE,\n",
    "                                   random_channel_swapping=CONFIG.RANDOM_CHANNEL_SWAPPING,\n",
    "                                   random_gamma=CONFIG.RANDOM_GAMMA,\n",
    "                                   random_resolution=CONFIG.RANDOM_RESOLUTION)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=N_WORKERS,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=train_align_collate,\n",
    "                          sampler=None,\n",
    "                         )\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=N_WORKERS,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=val_align_collate,\n",
    "                         )\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=N_WORKERS,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=None,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for image, label, image_file in train_loader:\n",
    "# for label_sentence, image_file in train_loader:\n",
    "for image, word_vectors_tensor in train_loader:\n",
    "#     print(label_sentence, image_file)\n",
    "    print(\"IMAGE:\", image.shape)\n",
    "    print(\"WV:\", word_vectors_tensor.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(image)[1].transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(img <= 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(img >= -1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-77a7949ba908>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = ImageBatchSampler('united', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = batch_sampler.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N LABEL GROUP (0, 5]\n",
      "\tWIDTH GROUP (0, 500]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 2072 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 7162 samples\n",
      "\tWIDTH GROUP (500, 700]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 750 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 1827 samples\n",
      "\tWIDTH GROUP (700, 1000]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 4112 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 1633 samples\n",
      "\tWIDTH GROUP (1000, 10000]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 191 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 1540 samples\n",
      "\n",
      "N LABEL GROUP (5, 7]\n",
      "\tWIDTH GROUP (0, 500]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 1328 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 6970 samples\n",
      "\tWIDTH GROUP (500, 700]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 777 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 1763 samples\n",
      "\tWIDTH GROUP (700, 1000]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 4706 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 1694 samples\n",
      "\tWIDTH GROUP (1000, 10000]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 101 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 769 samples\n",
      "\n",
      "N LABEL GROUP (7, 11]\n",
      "\tWIDTH GROUP (0, 500]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 1088 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 6451 samples\n",
      "\tWIDTH GROUP (500, 700]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 738 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 1922 samples\n",
      "\tWIDTH GROUP (700, 1000]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 4297 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 1605 samples\n",
      "\tWIDTH GROUP (1000, 10000]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 113 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 1200 samples\n",
      "\n",
      "N LABEL GROUP (11, 1000]\n",
      "\tWIDTH GROUP (0, 500]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 634 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 2647 samples\n",
      "\tWIDTH GROUP (500, 700]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 229 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 890 samples\n",
      "\tWIDTH GROUP (700, 1000]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 1307 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 835 samples\n",
      "\tWIDTH GROUP (1000, 10000]\n",
      "\t\tHEIGHT GROUP (0, 590]\n",
      "\t\t\t 154 samples\n",
      "\t\tHEIGHT GROUP (590, 10000]\n",
      "\t\t\t 2299 samples\n"
     ]
    }
   ],
   "source": [
    "## Group batches\n",
    "df_n_labels_grouped = df.groupby(by=pd.cut(df['n_labels'], [0, 5, 7, 11, 1000]))\n",
    "for key1, item1 in df_n_labels_grouped:\n",
    "    print(\"\\nN LABEL GROUP\", key1)\n",
    "    df1 = df_n_labels_grouped.get_group(key1)\n",
    "    df_width_grouped = df1.groupby(by=pd.cut(df1['width'], [0, 500, 700, 1000, 10000]))\n",
    "    for key2, item2 in df_width_grouped:\n",
    "        print(\"\\tWIDTH GROUP\", key2)\n",
    "        df2 = df_width_grouped.get_group(key2)\n",
    "        df_height_grouped = df2.groupby(by=pd.cut(df2['height'], [0, 590, 10000]))\n",
    "        for key3, item3 in df_height_grouped:\n",
    "            print(\"\\t\\tHEIGHT GROUP\", key3)\n",
    "#             print(df_height_grouped.get_group(key3), \"\\n\\n\")\n",
    "            print('\\t\\t\\t', len(df_height_grouped.get_group(key3).index), 'samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "for batch in batch_sampler:\n",
    "    batches.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1092, 1126, 1132, 1141]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 10\n",
    "batches[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>n_labels</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>data/wikiart/images/0063588.jpeg</td>\n",
       "      <td>495</td>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>data/wikiart/images/0049695.jpeg</td>\n",
       "      <td>305</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>data/wikiart/images/0001607.jpeg</td>\n",
       "      <td>300</td>\n",
       "      <td>364</td>\n",
       "      <td>4</td>\n",
       "      <td>1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>data/wikiart/images/0023579.jpeg</td>\n",
       "      <td>306</td>\n",
       "      <td>467</td>\n",
       "      <td>5</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_file  width  height  n_labels  index\n",
       "1092  data/wikiart/images/0063588.jpeg    495     512         4   1092\n",
       "1126  data/wikiart/images/0049695.jpeg    305     500         4   1126\n",
       "1132  data/wikiart/images/0001607.jpeg    300     364         4   1132\n",
       "1141  data/wikiart/images/0023579.jpeg    306     467         5   1141"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['index'].isin(batches[index])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63832"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51144"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12786 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15958"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "63832 // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for group in batch_sampler.groups:\n",
    "    s += len(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63831"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-cpu",
   "language": "python",
   "name": "pytorch-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
