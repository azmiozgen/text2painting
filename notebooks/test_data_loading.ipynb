{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "import glob\n",
    "from multiprocessing import cpu_count\n",
    "import os\n",
    "import sys\n",
    "\n",
    "## 3rd party\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFilter\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "_path = \"..\"\n",
    "if _path not in sys.path:\n",
    "    sys.path.append(_path)\n",
    "from lib.dataset import TextArtDataLoader, AlignCollate, ImageBatchSampler\n",
    "from lib.config import Config\n",
    "# from lib.preprocess import (pad_image, crop_edges_lr, )\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD2VEC_MODEL_FILE = \"../models/united_word2vec.model\"\n",
    "BATCH_SIZE = 4\n",
    "# N_WORKERS = cpu_count() - 1\n",
    "N_WORKERS = 1\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integeral value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-decdf118e432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                           \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_WORKERS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                           \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                           \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_align_collate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m#                           sampler=None,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                          )\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn)\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             raise ValueError(\"num_samples should be a positive integeral \"\n\u001b[0;32m---> 64\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise ValueError(\"replacement should be a boolean value, but got \"\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integeral value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "train_dataset = TextArtDataLoader('united', WORD2VEC_MODEL_FILE, mode='train')\n",
    "val_dataset = TextArtDataLoader('united', WORD2VEC_MODEL_FILE, mode='val')\n",
    "test_dataset = TextArtDataLoader('united', WORD2VEC_MODEL_FILE, mode='test')\n",
    "train_align_collate = AlignCollate('train',\n",
    "                                   CONFIG.MEAN,\n",
    "                                   CONFIG.STD,\n",
    "                                   CONFIG.IMAGE_SIZE_HEIGHT,\n",
    "                                   CONFIG.IMAGE_SIZE_WIDTH,\n",
    "                                   horizontal_flipping=CONFIG.HORIZONTAL_FLIPPING,\n",
    "                                   random_rotation=CONFIG.RANDOM_ROTATION,\n",
    "                                   color_jittering=CONFIG.COLOR_JITTERING,\n",
    "                                   random_grayscale=CONFIG.RANDOM_GRAYSCALE,\n",
    "                                   random_channel_swapping=CONFIG.RANDOM_CHANNEL_SWAPPING,\n",
    "                                   random_gamma=CONFIG.RANDOM_GAMMA,\n",
    "                                   random_resolution=CONFIG.RANDOM_RESOLUTION)\n",
    "val_align_collate = AlignCollate('val',\n",
    "                                   CONFIG.MEAN,\n",
    "                                   CONFIG.STD,\n",
    "                                   CONFIG.IMAGE_SIZE_HEIGHT,\n",
    "                                   CONFIG.IMAGE_SIZE_WIDTH,\n",
    "                                   horizontal_flipping=CONFIG.HORIZONTAL_FLIPPING,\n",
    "                                   random_rotation=CONFIG.RANDOM_ROTATION,\n",
    "                                   color_jittering=CONFIG.COLOR_JITTERING,\n",
    "                                   random_grayscale=CONFIG.RANDOM_GRAYSCALE,\n",
    "                                   random_channel_swapping=CONFIG.RANDOM_CHANNEL_SWAPPING,\n",
    "                                   random_gamma=CONFIG.RANDOM_GAMMA,\n",
    "                                   random_resolution=CONFIG.RANDOM_RESOLUTION)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=N_WORKERS,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=train_align_collate,\n",
    "#                           sampler=None,\n",
    "                         )\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=N_WORKERS,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=val_align_collate,\n",
    "                         )\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=N_WORKERS,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=None,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for image, label, image_file in train_loader:\n",
    "# for label_sentence, image_file in train_loader:\n",
    "for image, word_vectors_tensor in train_loader:\n",
    "#     print(label_sentence, image_file)\n",
    "    print(\"IMAGE:\", image.shape)\n",
    "    print(\"WV:\", word_vectors_tensor.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(image)[1].transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(img <= 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(img >= -1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = ImageBatchSampler('united', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = batch_sampler.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Group batches\n",
    "df_n_labels_grouped = df.groupby(by=pd.cut(df['n_labels'], [0, 5, 7, 11, 1000]))\n",
    "for key1, item1 in df_n_labels_grouped:\n",
    "    print(\"\\nN LABEL GROUP\", key1)\n",
    "    df1 = df_n_labels_grouped.get_group(key1)\n",
    "    df_width_grouped = df1.groupby(by=pd.cut(df1['width'], [0, 500, 700, 1000, 10000]))\n",
    "    for key2, item2 in df_width_grouped:\n",
    "        print(\"\\tWIDTH GROUP\", key2)\n",
    "        df2 = df_width_grouped.get_group(key2)\n",
    "        df_height_grouped = df2.groupby(by=pd.cut(df2['height'], [0, 590, 10000]))\n",
    "        for key3, item3 in df_height_grouped:\n",
    "            print(\"\\t\\tHEIGHT GROUP\", key3)\n",
    "#             print(df_height_grouped.get_group(key3), \"\\n\\n\")\n",
    "            print('\\t\\t\\t', len(df_height_grouped.get_group(key3).index), 'samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "for batch in batch_sampler:\n",
    "    batches.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10\n",
    "batches[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['index'].isin(batches[index])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12786 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "63832 // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for group in batch_sampler.groups:\n",
    "    s += len(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
