{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "import glob\n",
    "from multiprocessing import cpu_count\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "## 3rd party\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFilter\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "_path = \"..\"\n",
    "if _path not in sys.path:\n",
    "    sys.path.append(_path)\n",
    "from lib.dataset import TextArtDataLoader, AlignCollate, ImageBatchSampler\n",
    "from lib.config import Config\n",
    "# from lib.preprocess import (pad_image, crop_edges_lr, )\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "# N_WORKERS = cpu_count() - 1\n",
    "N_WORKERS = 0\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextArtDataLoader(CONFIG, mode='train')\n",
    "# val_dataset = TextArtDataLoader(CONFIG, mode='val')\n",
    "# test_dataset = TextArtDataLoader(CONFIG, mode='test')\n",
    "\n",
    "train_align_collate = AlignCollate(CONFIG, 'train')\n",
    "# val_align_collate = AlignCollate(CONFIG, 'val')\n",
    "\n",
    "# train_batch_sampler = ImageBatchSampler(CONFIG, mode='train')\n",
    "# val_batch_sampler = ImageBatchSampler(CONFIG, mode='val')\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=N_WORKERS,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=train_align_collate,\n",
    "#                           sampler=train_batch_sampler,\n",
    "                          drop_last=True,\n",
    "                         )\n",
    "# val_loader = DataLoader(val_dataset,\n",
    "#                           batch_size=BATCH_SIZE,\n",
    "#                           shuffle=False,\n",
    "#                           num_workers=N_WORKERS,\n",
    "#                           pin_memory=True,\n",
    "#                           collate_fn=val_align_collate,\n",
    "#                           sampler=val_batch_sampler\n",
    "#                          )\n",
    "# test_loader = DataLoader(test_dataset,\n",
    "#                           batch_size=BATCH_SIZE,\n",
    "#                           shuffle=False,\n",
    "#                           num_workers=N_WORKERS,\n",
    "#                           pin_memory=True,\n",
    "#                           collate_fn=None,\n",
    "#                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WVs\n",
      "feather/0.994 vulture/0.988 animal/0.993 wing/0.995 bird/0.996 team/0.245 \n",
      "\n",
      "raptor/0.994 dinosaur/0.997 bird/0.996 wing/0.995 animal/0.993 tribune/0.427 \n",
      "\n",
      "obstacle/0.887 showjump/0.888 rider/0.923 horse/0.889 jumping/0.817 art/0.233 \n",
      "\n",
      "anime/0.992 happy/0.985 smile/0.990 female/0.993 girl/0.990 swamp/0.085 \n",
      "\n",
      "\n",
      "WVs\n",
      "beautiful/0.854 illustration/0.862 pink/0.754 female/0.857 light/0.851 white/0.254 \n",
      "\n",
      "sunlight/0.834 lighting/0.847 forest/0.818 scenery/0.906 equine/0.906 blue/0.351 \n",
      "\n",
      "prehistoric/0.758 animal/0.587 dinosaur/0.730 rex/0.727 theropod/1.000 christmas/0.269 \n",
      "\n",
      "skull/1.000 animal/1.000 horse/1.000 horn/1.000 unicorn/1.000 lonely/0.076 \n",
      "\n",
      "\n",
      "WVs\n",
      "rex/0.859 theropod/0.873 animal/0.758 white/0.745 dinosaur/0.861 leopard/0.144 \n",
      "\n",
      "conceptual/0.775 hat/0.823 war/0.865 watercolor/0.870 drawing/0.707 puffy/0.280 \n",
      "\n",
      "glory/0.862 gray/0.877 equine/0.941 dressage/0.949 horse/0.929 doctor/0.232 \n",
      "\n",
      "fish/0.888 prehistoric/0.870 science/0.879 marine/0.884 aquatic/0.889 ball/0.317 \n",
      "\n",
      "\n",
      "WVs\n",
      "animal/0.909 seal/0.917 aquatic/0.966 diver/0.968 shark/1.000 military/0.250 \n",
      "\n",
      "prehistoric/0.817 cat/0.771 animal/0.665 panthera/0.803 jaguar/0.738 child/0.239 \n",
      "\n",
      "nature/0.977 lake/0.976 sunrise/0.983 dragonfly/0.962 horse/0.989 arabian/0.368 \n",
      "\n",
      "cat/0.995 form/0.997 gold/0.994 coin/0.989 happy/0.994 leave/0.261 \n",
      "\n",
      "\n",
      "WVs\n",
      "ocean/0.738 bird/0.855 prehistoric/0.899 ocean/0.832 giant/0.911 mad/0.324 \n",
      "\n",
      "cute/0.993 sketch/0.993 animal/0.989 pony/0.986 cartoon/0.994 people/0.271 \n",
      "\n",
      "heavy/0.985 machine/0.986 war/0.988 war/0.988 gun/0.984 bull/0.145 \n",
      "\n",
      "head/0.992 chestnut/0.994 horse/0.996 portrait/0.996 animal/0.993 watercolor/0.134 \n",
      "\n",
      "\n",
      "WVs\n",
      "war/0.988 gun/0.984 heavy/0.985 machine/0.986 war/0.988 vet/0.279 \n",
      "\n",
      "pokemon/0.854 attack/0.812 dog/0.600 nature/0.762 big/0.703 story/0.168 \n",
      "\n",
      "girl/0.990 female/0.993 anime/0.992 cartoon/0.990 worried/1.000 pattern/0.169 \n",
      "\n",
      "white/1.000 arise/1.000 horse/1.000 horn/1.000 ramp/1.000 bone/0.286 \n",
      "\n",
      "\n",
      "WVs\n",
      "dad/0.761 love/0.848 dad/0.747 dad/0.755 dad/0.730 aquarium/0.346 \n",
      "\n",
      "dinosaur/0.875 animal/0.780 hairy/0.785 beak/0.727 head/0.756 shiny/0.143 \n",
      "\n",
      "fin/0.909 fish/0.916 fin/0.918 animal/0.796 scientific/0.900 look/0.132 \n",
      "\n",
      "fantasy/0.904 mottle/0.923 starry/0.906 animal/0.883 horse/0.918 theropod/0.272 \n",
      "\n",
      "\n",
      "WVs\n",
      "animal/0.791 beast/0.877 rex/0.880 prehistoric/0.899 attack/0.863 cloud/0.202 \n",
      "\n",
      "marine/0.884 biology/0.909 fish/0.888 arachnid/1.000 trilobite/1.000 tall/0.110 \n",
      "\n",
      "scientific/0.779 rex/0.736 rex/0.698 animal/0.612 dinosaur/0.751 toad/0.228 \n",
      "\n",
      "mare/1.000 red/1.000 equine/1.000 black/1.000 horse/1.000 fur/0.303 \n",
      "\n",
      "\n",
      "WVs\n",
      "portrait/0.989 female/0.992 beautiful/0.991 woman/0.987 white/0.978 angry/0.393 \n",
      "\n",
      "horse/0.934 knight/0.717 animal/0.864 rex/0.923 dinosaur/0.928 boy/0.305 \n",
      "\n",
      "horse/0.980 arabian/0.957 mare/0.977 gallop/0.979 chestnut/1.000 skyscraper/0.308 \n",
      "\n",
      "map/0.822 man/0.809 aquatic/0.900 animal/0.764 ocean/0.873 reef/0.360 \n",
      "\n",
      "\n",
      "WVs\n",
      "sonic/1.000 ash/0.999 pikachu/1.000 double/0.999 reverse/1.000 design/0.249 \n",
      "\n",
      "forest/0.994 pokemon/0.997 tree/0.995 baby/0.996 night/0.997 logo/0.204 \n",
      "\n",
      "combat/1.000 strike/1.000 aircraft/1.000 fighter/1.000 warfare/1.000 monocle/0.270 \n",
      "\n",
      "equine/0.965 fantasy/0.947 pegasus/0.950 horse/0.957 sunlight/0.933 tusk/0.324 \n",
      "\n",
      "\n",
      "WVs\n",
      "dinosaur/0.817 animal/0.697 theropod/0.833 drawing/0.742 fight/0.782 beach/0.336 \n",
      "\n",
      "beach/1.000 predator/1.000 sea/1.000 animal/1.000 hairy/1.000 team/0.214 \n",
      "\n",
      "beak/0.948 sketch/0.974 bird/0.974 river/0.941 animal/0.958 stag/0.132 \n",
      "\n",
      "heavy/0.985 gun/0.984 war/0.988 machine/0.986 war/0.988 couple/0.325 \n",
      "\n",
      "\n",
      "WVs\n",
      "mare/0.977 horse/0.980 myth/0.955 sand/0.971 fantasy/0.975 warden/0.187 \n",
      "\n",
      "female/0.997 character/0.995 girl/0.995 hair/0.993 sexy/0.996 book/0.278 \n",
      "\n",
      "animal/0.587 evolution/0.525 dinosaur/0.730 theropod/0.750 rex/0.727 nude/0.210 \n",
      "\n",
      "animal/0.993 portrait/0.996 mustang/0.982 dawn/0.982 horse/0.996 form/0.292 \n",
      "\n",
      "\n",
      "WVs\n",
      "animal/0.886 dinosaur/0.940 raptor/0.896 bird/0.926 lake/0.885 comic/0.239 \n",
      "\n",
      "horse/0.889 scenery/0.906 stallion/0.871 rearing/0.765 animal/0.849 eat/0.206 \n",
      "\n",
      "warfare/1.000 fighter/1.000 aircraft/1.000 combat/1.000 strike/1.000 pegasus/0.247 \n",
      "\n",
      "horse/0.977 black/0.964 foal/0.959 animal/0.962 heart/1.000 star/0.304 \n",
      "\n",
      "\n",
      "WVs\n",
      "black/0.964 horse/0.977 animal/0.962 antler/0.968 dark/0.961 antler/0.067 \n",
      "\n",
      "animal/0.858 myth/0.813 fantasy/0.881 horse/0.897 pegasus/0.887 pose/0.135 \n",
      "\n",
      "nature/0.966 horn/0.979 jumping/0.972 tail/0.976 horse/0.984 doctor/0.235 \n",
      "\n",
      "equine/0.906 equestrian/0.860 sunlight/0.834 horse/0.889 scenery/0.906 amphibia/0.420 \n",
      "\n",
      "\n",
      "WVs\n",
      "animal/0.921 sloth/0.898 hairy/0.920 skeleton/0.931 mega/1.000 tower/0.195 \n",
      "\n",
      "giant/0.820 animal/0.635 dinosaur/0.726 dinosaur/0.770 beast/0.758 spaceship/0.308 \n",
      "\n",
      "sonic/1.000 paint/1.000 team/1.000 color/0.999 pikachu/1.000 toad/0.306 \n",
      "\n",
      "cute/0.997 animal/0.995 cartoon/0.997 surprised/0.996 childish/0.997 beach/0.266 \n",
      "\n",
      "\n",
      "WVs\n",
      "female/0.993 sexy/0.991 anime/0.992 cartoon/0.990 watermelon/1.000 jungle/0.300 \n",
      "\n",
      "planet/0.925 orbit/0.945 futuristic/0.898 tower/0.862 space/0.917 funny/0.283 \n",
      "\n",
      "male/1.000 dark/0.999 handsome/0.999 portrait/1.000 unnatural/1.000 contest/0.272 \n",
      "\n",
      "horse/1.000 gray/1.000 animal/1.000 noble/1.000 uncolored/0.999 ominous/0.150 \n",
      "\n",
      "\n",
      "WVs\n",
      "forest/0.929 horse/0.961 winter/0.967 snow/0.961 fantasy/0.952 woman/0.229 \n",
      "\n",
      "fantasy/0.985 horse/0.990 tail/0.984 gallop/0.989 breed/0.990 tree/0.197 \n",
      "\n",
      "female/0.998 staff/0.998 mage/0.998 girl/0.998 hat/0.998 science/0.342 \n",
      "\n",
      "character/0.998 cartoon/0.998 hat/0.998 scarf/0.997 soldier/1.000 science/0.356 \n",
      "\n",
      "\n",
      "WVs\n",
      "girl/0.990 anime/0.992 female/0.993 smile/0.990 cartoon/0.990 dark/0.090 \n",
      "\n",
      "teeth/0.970 character/0.993 cat/0.991 happy/0.989 smile/0.992 christmas/0.238 \n",
      "\n",
      "horse/0.991 halter/0.989 environment/0.986 outdoor/0.989 ride/1.000 predator/0.345 \n",
      "\n",
      "prehistoric/0.758 dinosaur/0.682 head/0.561 animal/0.587 dinosaur/0.730 snow/0.162 \n",
      "\n",
      "\n",
      "WVs\n",
      "indoor/0.985 ride/0.989 equine/0.991 ride/0.989 gallop/0.989 antelope/0.335 \n",
      "\n",
      "animal/0.750 predator/0.845 wild/0.827 lion/0.828 cat/0.837 guy/0.148 \n",
      "\n",
      "diver/0.996 reptile/0.993 animal/0.988 sea/0.993 snake/0.992 raindrop/0.365 \n",
      "\n",
      "fantasy/0.975 horse/0.980 unicorn/0.972 antler/0.972 animal/0.967 bulb/0.319 \n",
      "\n",
      "\n",
      "WVs\n",
      "horse/0.985 hairy/0.971 field/0.978 run/0.975 gallop/0.984 rest/0.109 \n",
      "\n",
      "heavy/0.997 machine/0.998 armored/0.998 gun/0.997 tank/0.998 mushroom/0.212 \n",
      "\n",
      "foal/0.965 horse/0.980 gallop/0.979 run/0.968 stallion/1.000 grey/0.368 \n",
      "\n",
      "pokemon/0.971 green/0.939 small/0.916 cute/0.962 leaf/0.935 jump/0.346 \n",
      "\n",
      "\n",
      "WVs\n",
      "creature/0.990 dark/0.980 horse/0.990 fantasy/0.985 black/0.982 nude/0.465 \n",
      "\n",
      "white/0.957 concept/0.956 pokemon/0.979 cat/0.976 funny/0.963 doodle/0.296 \n",
      "\n",
      "ribbon/0.936 concept/0.939 dancing/0.889 pokemon/0.971 happy/0.956 paint/0.362 \n",
      "\n",
      "prehistoric/0.870 science/0.879 aquatic/0.889 fish/0.888 creature/0.863 forest/0.403 \n",
      "\n",
      "\n",
      "WVs\n",
      "equine/0.906 rider/0.923 hat/0.901 cowboy/0.884 horse/0.889 equine/0.091 \n",
      "\n",
      "jockey/0.900 horse/0.889 rider/0.923 trot/0.808 equine/0.906 leave/0.343 \n",
      "\n",
      "grave/0.997 technology/0.999 tunnel/0.996 science/0.999 fiction/0.999 horsemanship/0.200 \n",
      "\n",
      "aquatic/0.965 animal/0.906 giant/0.964 diver/0.967 whale/0.953 plant/0.213 \n",
      "\n",
      "\n",
      "WVs\n",
      "dark/0.973 scary/0.982 fear/0.977 black/0.976 mare/0.983 character/0.376 \n",
      "\n",
      "meadow/0.945 horse/0.980 chestnut/0.969 grass/0.950 realistic/0.971 nest/0.344 \n",
      "\n",
      "dinosaur/0.748 horn/0.689 scale/0.677 rex/0.746 animal/0.608 leave/0.237 \n",
      "\n",
      "warfare/1.000 fighter/1.000 aircraft/1.000 strike/1.000 combat/1.000 flower/0.112 \n",
      "\n",
      "\n",
      "WVs\n",
      "jumping/0.817 horse/0.889 scene/0.887 animal/0.850 rider/0.923 funny/0.183 \n",
      "\n",
      "puffy/0.996 pony/0.994 cartoon/0.997 animal/0.995 cute/0.997 bulb/0.331 \n",
      "\n",
      "dinosaur/0.806 theropod/0.854 animal/0.729 dinosaur/0.840 scientific/0.860 vet/0.265 \n",
      "\n",
      "dinosaur/0.751 animal/0.612 giant/0.803 scientific/0.779 theropod/0.769 spiral/0.090 \n",
      "\n",
      "\n",
      "WVs\n",
      "pegasus/0.887 horse/0.897 animal/0.858 myth/0.813 kitty/0.734 man/0.253 \n",
      "\n",
      "spring/0.994 horse/0.996 portrait/0.996 headshot/0.992 calm/0.991 tie/0.355 \n",
      "\n",
      "queen/0.997 crown/0.998 warlock/0.995 portrait/0.997 magician/0.996 monkey/0.184 \n",
      "\n",
      "raptor/0.621 theropod/0.768 dinosaur/0.749 prehistoric/0.776 animal/0.610 fly/0.281 \n",
      "\n",
      "\n",
      "WVs\n",
      "jumping/0.817 rider/0.923 glory/0.798 horse/0.889 sunlight/0.835 plant/0.329 \n",
      "\n",
      "fighter/1.000 sky/0.999 aircraft/1.000 strike/1.000 warfare/1.000 sea/0.169 \n",
      "\n",
      "portrait/1.000 horse/1.000 stallion/1.000 white/1.000 elegance/1.000 deer/0.068 \n",
      "\n",
      "animal/0.940 arthropod/0.964 shrimp/0.971 mollusk/0.972 real/1.000 family/0.272 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WVs\n",
      "primate/0.813 hairy/0.735 monkey/0.764 beast/0.831 baboon/0.597 blue/0.027 \n",
      "\n",
      "baby/0.931 sleep/0.950 worried/0.933 female/0.966 mother/0.945 heart/0.360 \n",
      "\n",
      "dinosaur/0.861 animal/0.758 rex/0.859 theropod/0.873 tyrannosaurus/0.714 teardrop/0.142 \n",
      "\n",
      "fighter/1.000 warfare/1.000 aircraft/1.000 combat/1.000 strike/1.000 weirdo/0.250 \n",
      "\n",
      "\n",
      "WVs\n",
      "winter/0.973 blizzard/0.934 black/0.951 dark/0.947 snow/0.969 cowboy/0.222 \n",
      "\n",
      "portrait/0.996 horse/0.996 animal/0.993 stallion/1.000 mane/1.000 cute/0.310 \n",
      "\n",
      "scene/0.939 stable/0.929 outdoor/0.931 environment/0.908 switzerland/1.000 meat/0.274 \n",
      "\n",
      "bulb/0.998 cartoon/0.998 light/0.998 hat/0.998 character/0.998 horde/0.228 \n",
      "\n",
      "\n",
      "WVs\n",
      "child/0.999 stylish/0.999 girl/0.999 portrait/0.999 dress/0.995 sea/0.303 \n",
      "\n",
      "head/0.756 life/0.671 animal/0.780 drawing/0.823 dinosaur/0.875 fire/0.331 \n",
      "\n",
      "bird/0.974 jungle/0.968 ostrich/0.928 drawing/0.971 jungle/1.000 science/0.347 \n",
      "\n",
      "angry/0.996 couple/0.995 mad/0.996 fire/0.996 protect/0.991 serpent/0.108 \n",
      "\n",
      "\n",
      "WVs\n",
      "rider/0.937 scene/0.906 dark/0.860 horse/0.908 animal/0.871 blood/0.163 \n",
      "\n",
      "aqua/0.879 aquarium/0.959 pokemon/0.951 bottle/0.926 aquarium/1.000 orphan/0.270 \n",
      "\n",
      "aircraft/1.000 fighter/1.000 warfare/1.000 strike/1.000 combat/1.000 ship/0.344 \n",
      "\n",
      "underwater/0.994 dinosaur/0.990 fish/0.993 aqautic/0.943 animal/0.981 rest/0.290 \n",
      "\n",
      "\n",
      "WVs\n",
      "strike/1.000 fighter/1.000 sky/0.999 warfare/1.000 aircraft/1.000 hippodrome/0.231 \n",
      "\n",
      "animal/0.614 prehistoric/0.779 scientific/0.783 raptor/0.626 dinosaur/0.753 shadow/0.301 \n",
      "\n",
      "ramp/0.982 animal/0.973 horse/0.984 tail/0.976 stand/0.968 ramp/0.186 \n",
      "\n",
      "girl/0.990 anime/0.992 cute/0.987 female/0.993 kneel/0.944 blonde/0.362 \n",
      "\n",
      "\n",
      "WVs\n",
      "machine/0.986 war/0.988 war/0.988 heavy/0.985 gun/0.984 nature/0.361 \n",
      "\n",
      "couple/0.982 female/0.993 cartoon/0.990 sexy/0.991 anime/0.992 baby/0.151 \n",
      "\n",
      "animal/0.796 fish/0.916 scientific/0.900 fin/0.918 fin/0.909 look/0.193 \n",
      "\n",
      "fish/0.960 diving/0.942 diver/0.963 swim/0.955 giant/0.959 sketch/0.306 \n",
      "\n",
      "\n",
      "WVs\n",
      "animal/0.808 aquatic/0.922 marine/0.919 shell/0.875 octopus/1.000 leopard/0.174 \n",
      "\n",
      "fish/0.916 fin/0.909 fin/0.918 animal/0.796 scientific/0.900 mad/0.244 \n",
      "\n",
      "aircraft/1.000 warfare/1.000 sky/0.999 strike/1.000 fighter/1.000 sea/0.260 \n",
      "\n",
      "halter/0.999 mad/0.998 furious/0.998 rearing/0.996 dressage/0.999 sketch/0.114 \n",
      "\n",
      "\n",
      "WVs\n",
      "mule/0.995 horse/0.996 tail/0.993 horse/0.996 breed/0.996 fauna/0.225 \n",
      "\n",
      "girl/0.953 guy/0.919 female/0.964 hold/0.953 male/0.932 coat/0.168 \n",
      "\n",
      "equine/0.991 sooty/0.982 mare/0.987 horse/0.989 animal/0.982 art/0.241 \n",
      "\n",
      "brown/0.994 horse/0.996 sunlight/0.994 portrait/0.996 nature/0.992 double/0.340 \n",
      "\n",
      "\n",
      "WVs\n",
      "sonic/1.000 paint/1.000 cartoon/0.999 leap/1.000 happy/1.000 horn/0.189 \n",
      "\n",
      "splash/0.776 horse/0.889 woman/0.881 rider/0.923 cross/0.797 royal/0.393 \n",
      "\n",
      "horse/0.970 animal/0.939 stallion/0.966 house/0.963 building/0.949 fox/0.299 \n",
      "\n",
      "sky/0.999 warfare/1.000 aircraft/1.000 strike/1.000 jet/1.000 hat/0.183 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b8852a06b583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minv_normalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInvNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_wv_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     for image in images:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#         print(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch1.3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/text2painting/lib/dataset.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mimages_first\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/text2painting/lib/dataset.py\u001b[0m in \u001b[0;36m__preprocess\u001b[0;34m(self, image, first)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImageFilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m## Pad or crop_lr image with low prob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch1.3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, filter)\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mmultiband\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultibandFilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbands\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmultiband\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m         \u001b[0mims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch1.3/lib/python3.7/site-packages/PIL/ImageFilter.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_blur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inv_normalize = InvNormalize(CONFIG.MEAN, CONFIG.STD)\n",
    "for i, (images_first, images, wv_tensor, fake_wv_tensor) in enumerate(train_loader):\n",
    "\n",
    "#     for image in images:\n",
    "#         print(image)\n",
    "#         print(\"MIN:\", image.min())\n",
    "#         print(\"MAX:\", image.max())\n",
    "#         print()\n",
    "\n",
    "#     print(\"IMAGE:\", images.shape)\n",
    "#     print(\"WV:\", wv_tensor.shape)\n",
    "#     print(\"Fake WV:\", fake_wv_tensor.shape)\n",
    "    \n",
    "    print(\"\\nWVs\")\n",
    "    for wvs in wv_tensor:\n",
    "        for wv in wvs:\n",
    "            wv = np.array(wv)\n",
    "            word, prob = train_loader.dataset.word2vec_model.wv.similar_by_vector(wv)[0]\n",
    "            print(\"{}/{:.3f}\".format(word, prob), end=' ')\n",
    "        print('\\n')\n",
    "    \n",
    "#     print(\"-------------\")\n",
    "#     print(\"\\nFake WVs\")\n",
    "#     for fake_wvs in fake_wv_tensor:\n",
    "#         for fake_wv in fake_wvs:\n",
    "#             fake_wv = np.array(fake_wv)\n",
    "#             fake_word, prob = train_loader.dataset.word2vec_model.wv.similar_by_vector(fake_wv)[0]\n",
    "#             print(\"{}/{:.3f}\".format(fake_word, prob), end=' ')\n",
    "#         print('\\n')\n",
    "    \n",
    "#     for image in images:\n",
    "#         image = inv_normalize(image)\n",
    "#         image = np.array(image)\n",
    "#         image = image.transpose(1, 2, 0)\n",
    "#         plt.figure(figsize=(6, 6))\n",
    "#         plt.imshow(image)\n",
    "#         plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "def words2image(text_list, n_column=1):\n",
    "    config = Config()\n",
    "\n",
    "    w = config.IMAGE_SIZE_WIDTH\n",
    "    h = config.IMAGE_SIZE_HEIGHT\n",
    "\n",
    "    img = Image.fromarray(np.ones((h, w)))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    ## Look for fonts\n",
    "    for font in config.FONTS:\n",
    "        try:\n",
    "            font = ImageFont.truetype(font, 9)\n",
    "        except OSError:\n",
    "            continue\n",
    "    \n",
    "    if n_column == 1:\n",
    "        \n",
    "        x0 = int(w * 0.001)\n",
    "        y0 = int(h * 0.001)\n",
    "        word_height = h // len(text_list)\n",
    "        for i, text in enumerate(text_list):\n",
    "            y = i * word_height + y0\n",
    "            x = x0\n",
    "            draw.text((x, y), text, 0, font=font)\n",
    "\n",
    "    elif n_column == 2:\n",
    "        \n",
    "        x1 = int(w * 0.01)\n",
    "        x2 = int(w * 0.51)\n",
    "        y0 = int(h * 0.01)\n",
    "        word_height = h // len(text_list) * 2\n",
    "        for i, text in enumerate(text_list):\n",
    "            y = (i // 2) * word_height + y0 if i % 2 == 0 else (i - 1) // 2 * word_height + y0\n",
    "            x = x1 if i % 2 == 0 else x2\n",
    "            draw.text((x, y), text, 0, font=font)\n",
    "            \n",
    "    else:\n",
    "        print(\"'words2image': Column {} not implemented\".format(n_column))\n",
    "        raise NotImplemented\n",
    "\n",
    "    return np.array(img.convert('RGB')) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images_bag = []\n",
    "for i, (fake_image, real_wvs) in enumerate(zip(images, wv_tensor)):\n",
    "    words = []\n",
    "    for real_wv in real_wvs:\n",
    "        real_wv = np.array(real_wv)\n",
    "        word, prob = train_dataset.word2vec_model.wv.similar_by_vector(real_wv)[0]\n",
    "        words.append(word)\n",
    "\n",
    "    fake_image = np.array(fake_image).transpose(1, 2, 0)\n",
    "    word_image = words2image(words)\n",
    "    \n",
    "    images_bag.extend([word_image, fake_image])\n",
    "    \n",
    "images_bag = np.array(images_bag)\n",
    "words = np.unique(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test image batch sampling\n",
    "sampler = ImageBatchSampler(CONFIG)\n",
    "# for i in range(len(train_dataset)):\n",
    "#     x = \"/\".join(train_dataset[i][2].split('/')[-4:])\n",
    "#     y = sampler.df[sampler.df['index'] == i]['image_file'].iloc[0]\n",
    "#     if x != y:\n",
    "#         print(x, y)\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.3",
   "language": "python",
   "name": "pytorch1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
